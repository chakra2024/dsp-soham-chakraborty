{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07d99268-1579-4183-b249-18d3a2893264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c277e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "\n",
    "DATA_FILENAME = 'C:/Users/SOHAM/dsp-soham-chakraborty/data/train.csv'\n",
    "MODEL_PATH = 'C:/Users/SOHAM/dsp-soham-chakraborty/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b2c9f-c0be-4024-a1c7-1167cc732806",
   "metadata": {},
   "source": [
    "## Model Build Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb3c23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data: pd.DataFrame) -> dict:\n",
    " \n",
    "    # Select useful features\n",
    "    label_col = 'SalePrice'\n",
    "    useful_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd', 'ExterQual']\n",
    "   \n",
    "    # Select features and label for training data\n",
    "    useful_data = data[useful_features + [label_col]]\n",
    "    \n",
    "    # Split data to avoid leakage\n",
    "    train_df, test_df = train_test_split(useful_data, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "    # Preprocess data\n",
    "    continuous_features = ['GrLivArea', 'GarageCars', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd']\n",
    "    ordinal_feature = 'ExterQual'\n",
    "    \n",
    "    # Ordinal Encoding\n",
    "    exterior_quality_dict = {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1}\n",
    "    train_df[ordinal_feature] = train_df[ordinal_feature].apply(lambda x: exterior_quality_dict.get(x, np.nan))\n",
    "    test_df[ordinal_feature] = test_df[ordinal_feature].apply(lambda x: exterior_quality_dict.get(x, np.nan))\n",
    "\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_df[continuous_features])\n",
    "    train_scaled = scaler.transform(train_df[continuous_features])\n",
    "    test_scaled = scaler.transform(test_df[continuous_features])\n",
    "\n",
    "    # Combine preprocessed features\n",
    "    train_preprocessed = pd.concat([\n",
    "        pd.DataFrame(train_scaled, columns=continuous_features),\n",
    "        train_df[ordinal_feature].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    test_preprocessed = pd.concat([\n",
    "        pd.DataFrame(test_scaled, columns=continuous_features),\n",
    "        test_df[ordinal_feature].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_preprocessed, train_df[label_col])\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(test_preprocessed)\n",
    "    rmse = np.sqrt(mean_squared_error(test_df[label_col], y_pred))\n",
    "    return {'rmse': rmse}\n",
    "    #print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "    # Saving the model and scaler\n",
    "    joblib.dump(model, os.path.join(MODEL_PATH, 'model.joblib'))\n",
    "    joblib.dump(scaler, os.path.join(MODEL_PATH, 'scaler.joblib'))\n",
    "\n",
    "    return {'rmse': rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc901b",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f5be9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for making predictions on new data\n",
    "\n",
    "def make_predictions(input_data: pd.DataFrame) -> np.ndarray:\n",
    "    # Features used during model training\n",
    "    continuous_features = ['GrLivArea', 'GarageCars', 'FullBath', 'YearBuilt', 'YearRemodAdd']\n",
    "    ordinal_feature = 'ExterQual'\n",
    "    exterior_quality_dict = {'Ex': 4, 'Gd': 3, 'TA': 2, 'Fa': 1}\n",
    "\n",
    "    # Load scaler and model\n",
    "    scaler = joblib.load(os.path.join(MODEL_PATH, 'scaler.joblib'))\n",
    "    model = joblib.load(os.path.join(MODEL_PATH, 'model.joblib'))\n",
    "\n",
    "    # Preprocess ordinal feature\n",
    "    input_data[ordinal_feature] = input_data[ordinal_feature].apply(lambda x: exterior_quality_dict.get(x, np.nan))\n",
    "\n",
    "    # Ensure the test data has the same features as the training data\n",
    "    input_data_subset = input_data[continuous_features + [ordinal_feature]]\n",
    "\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    input_data_imputed = pd.DataFrame(imputer.fit_transform(input_data_subset), columns=input_data_subset.columns)\n",
    "\n",
    "    # Apply the scaler to the continuous features\n",
    "    input_scaled = scaler.transform(input_data_imputed[continuous_features])\n",
    "\n",
    "    # Combine scaled continuous features and ordinal feature into a DataFrame\n",
    "    input_preprocessed = pd.concat([\n",
    "        pd.DataFrame(input_scaled, columns=continuous_features),\n",
    "        input_data_imputed[ordinal_feature].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(input_preprocessed)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae01ef",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51f96f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 42793.603797757896}\n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "training_data_df = pd.read_csv(DATA_FILENAME)\n",
    "model_performance_dict = build_model(training_data_df)\n",
    "print(model_performance_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b923b2",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d99ce09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101872.6718482  129607.08349072 189739.96063635 ... 157001.48484206\n",
      " 107617.70951989 234409.30836151]\n"
     ]
    }
   ],
   "source": [
    "# Model Inference\n",
    "test_data_path = 'C:/Users/SOHAM/dsp-soham-chakraborty/data/test.csv'\n",
    "new_data_df = pd.read_csv(test_data_path)\n",
    "predictions = make_predictions(new_data_df)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a26af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
